---
name: pbt-ir
description: Analyze a library function's documentation to produce a structured IR (JSON) and a properties_to_test.md. The IR is the quality gate before test generation — it classifies what is testable, what is ambiguous, and what is broken. Always produces a JSON, even if logical errors are found.
---

# Property-Based Testing IR Generator

Produce a structured IR JSON and a properties markdown file for a library function. The IR is the input to a downstream test generation agent. Always produce the JSON — even if there are logical errors, the record is valuable for later analysis.
your goal is not writing your own test cases, but producing a IR for downstream test generation agent.

**Outputs**:
- `ir/<library>/<function>.json`
- `ir/<library>/<function>_properties.md` (generated by `generate_properties_md.py`)

---

## Step 1 — Fetch Documentation (Optional)

Skip this step if the user provides documentation directly.

If not provided, fetch the full docstring, signature, and version. Load existing module notes if available.

```bash
uv run python -c "import pandas as pd; help(pd.DataFrame.merge)"
cat notes/<library>.md 2>/dev/null || echo "no prior notes"
```

---

## Step 2 — Logical Errors and Ambiguities (Always First)

Read the documentation and classify issues before writing anything else. **Always continue and produce a JSON** — logical errors and ambiguities are recorded in the IR, not treated as blockers.

**Logical errors** — documentation contradicts itself, states something demonstrably false, or has contradictory parameter descriptions. Record each error. Note in the JSON whether it is severe enough to make the specification untrustworthy. Properties can still be extracted from the parts of the spec that are sound.

**Ambiguities** — behavior that is underspecified. For each ambiguity:
1. Search GitHub issues and changelog for design intent:
   ```bash
   gh issue list --repo <org>/<repo> --search "<topic>" --state all
   ```
2. If resolved: carry into properties with type `ambiguity`, mark source
3. If unresolved: exclude from input domain and properties, record in `unresolved_ambiguities`

---

## Step 3 — Input Domain

Define valid and invalid inputs. This becomes `assume()` calls and `@given` strategies in the generated tests.

The input domain is the universal precondition for all properties. A property's `when` field captures any narrower condition beyond this.

```json
"input_domain": {
  "right": "DataFrame or named Series",
  "how": "one of: 'left', 'right', 'inner', 'outer', 'cross'",
  "on": "str or list[str], must exist in both frames; None means join on index",
  "constraints": [
    "on and left_on/right_on are mutually exclusive"
  ],
  "invalid_inputs": [
    "how='cross' with on specified → raises MergeError",
    "on column not present in both frames → raises KeyError"
  ]
}
```

Omit parameters that are unresolved ambiguities.

---

## Step 4 — Properties to Test

Extract claims and specify each one formally. Each property has a **type** (where the claim comes from) and a **strategy** (what inputs to use and what to look for).

### Property Types

| type | meaning |
|---|---|
| `explicit` | directly and clearly stated in the docstring |
| `indirect` | stated but requires interpretation of phrasing or examples |
| `implicit` | logically follows from the spec but not stated outright |
| `convention` | library-wide pattern not specific to this function; loaded from module notes |
| `ambiguity` | was ambiguous, resolved via search |

### Strategy Field

The strategy specifies:
- **what inputs** to generate (valid, invalid, edge cases, specific parameter combinations)
- **what to look for** (assertion shape, comparison, exception type)

This is not Hypothesis code — it is a precise English description that tells the test-writing agent what to do.

don't trying to looking for specific error messages.

### Property Schema

```json
{
  "id": "P<n>",
  "type": "explicit | indirect | implicit | convention | ambiguity",
  "claim": "close paraphrase of the doc claim, or inferred claim",
  "expression": "Python expression fragment usable as assertion skeleton",
  "when": "narrower precondition beyond the input domain, or null",
  "strategy": "what inputs to generate and what behavior to check for",
  "source": null
}
```

### Example Properties

```json
"properties": [
  {
    "id": "P1",
    "type": "explicit",
    "claim": "inner join result contains only rows where key appears in both frames",
    "expression": "set(result[on]) <= set(left[on]) & set(right[on])",
    "when": "how='inner', on is a single column present in both frames",
    "strategy": "generate two DataFrames with a shared column of mixed overlapping and non-overlapping string keys. Assert result keys are the intersection.",
    "source": null
  },
  {
    "id": "P2",
    "type": "explicit",
    "claim": "invalid value for how raises ValueError",
    "expression": "pytest.raises(ValueError): df.merge(right, how=<invalid>)",
    "when": null,
    "strategy": "pass arbitrary strings not in the valid set, integers, None, and lists. Each should raise ValueError or TypeError. Check that valid values never raise.",
    "source": null
  },
  {
    "id": "P3",
    "type": "implicit",
    "claim": "result column count equals sum of unique columns from both frames minus join key (appears once)",
    "expression": "len(result.columns) == len(set(left.columns) | set(right.columns))",
    "when": "no overlapping non-key columns, so no suffix needed",
    "strategy": "generate DataFrames with disjoint column sets except the key. Count columns in result and compare to expected.",
    "source": null
  },
  {
    "id": "P4",
    "type": "convention",
    "claim": "result index is reset to RangeIndex regardless of input index",
    "expression": "isinstance(result.index, pd.RangeIndex)",
    "when": null,
    "strategy": "pass DataFrames with non-default index (DatetimeIndex, string index, MultiIndex). Assert result always has a default integer RangeIndex.",
    "source": "notes/pandas.md: most DataFrame operations reset index by default"
  },
  {
    "id": "P5",
    "type": "ambiguity",
    "claim": "empty string suffix does not raise even when column names would collide",
    "expression": "df.merge(right, suffixes=('', '')) does not raise",
    "when": "both frames share non-key column names",
    "strategy": "generate DataFrames with identical non-key column names. Pass suffixes=('', ''). Assert no exception. Note: result may have duplicate column names — check this is the actual behavior.",
    "source": "gh#45678"
  }
]
```

---

## Step 5 — Unresolved Ambiguities

List behaviors excluded from testing. Do not invent properties for these.

```json
"unresolved_ambiguities": [
  {
    "id": "A1",
    "description": "behavior when both 'on' and 'left_on' are passed simultaneously",
    "maintainer_note": "merge() does not document behavior when both 'on' and 'left_on' are provided. Empirically raises MergeError in v2.1.0 but this is absent from the docstring. Recommend adding to Raises section."
  }
]
```

---

## Step 6 — Update Module Notes

Append new conventions and patterns to `notes/<library>.md`. Loaded at Step 1 of future runs.

```markdown
<!-- notes/pandas.md -->
- Index reset: most DataFrame ops produce a RangeIndex unless ignore_index=False or index-preserving op.
- NaN in join keys: inner join silently drops NaN-keyed rows. Not documented per-function.
- Hypothesis: use hypothesis.extra.pandas (st.data_frames) not raw st.lists() for typed DataFrames.
```

---

## Step 7 — Generate the Markdown

```bash
uv run python .claude/skills/property-test-w-ir/scripts/generate_properties_md.py ir/<library>/<function>.json
# outputs: ir/<library>/<function>_properties.md
```

---

## Full IR Schema

```json
{
  "metadata": {
    "function": "pd.DataFrame.merge",
    "library": "pandas",
    "version": "2.1.0",
    "signature": "merge(right, how='inner', on=None, ...)"
  },
  "logical_errors": [
    {
      "id": "E<n>",
      "description": "what is wrong",
      "severity": "severe | minor",
      "affects_properties": ["P<n>"] 
    }
  ],
  "input_domain": {
    "<param>": "description",
    "constraints": [],
    "invalid_inputs": []
  },
  "properties": [
    {
      "id": "P<n>",
      "type": "explicit | indirect | implicit | convention | ambiguity",
      "claim": "close paraphrase of the claim",
      "expression": "Python expression fragment",
      "when": "narrower precondition or null",
      "strategy": "what inputs to generate and what to check for",
      "source": null
    }
  ],
  "unresolved_ambiguities": [
    {
      "id": "A<n>",
      "description": "what is unclear",
      "maintainer_note": "concise developer-readable gap description"
    }
  ]
}
```