{
  "metadata": {
    "library": "pandas",
    "version": "3.0.0",
    "function": "pd.DataFrame.reindex",
    "references": [
      {
        "id": "R1",
        "type": "api_doc",
        "url": "https://pandas.pydata.org/pandas-docs/version/3.0.0/reference/api/pandas.DataFrame.reindex.html"
      }
    ]
  },
  "pre_conditions": {
    "labels": {
      "type": "array-like or None",
      "partitions": {
        "L0": {
          "desc": "None — parameter not provided, axis selection falls to index/columns kwargs",
          "example": "None"
        },
        "L1": {
          "desc": "subset of original index labels — some labels removed, none added",
          "example": "['Safari', 'Chrome']  # original had 5 rows"
        },
        "L2": {
          "desc": "superset of original index — all original labels present plus new ones",
          "example": "['Safari', 'Iceweasel', 'Chrome', 'NewBrowser']"
        },
        "L3": {
          "desc": "fully disjoint — no overlap with original index at all",
          "example": "['X', 'Y', 'Z']  # original had ['a','b','c']"
        },
        "L4": {
          "desc": "identical to original index in same order — identity reindex",
          "example": "list(df.index)"
        },
        "L5": {
          "desc": "empty list — result should have zero rows",
          "example": "[]"
        }
      },
      "interaction_hints": ["axis", "index", "columns"],
      "invalid_cases": []
    },
    "index": {
      "type": "array-like or None",
      "partitions": {
        "X0": {
          "desc": "None — row index not changed via this kwarg",
          "example": "None"
        },
        "X1": {
          "desc": "non-empty array-like — new row labels including at least one new label",
          "example": "['Safari', 'NewBrowser', 'Chrome']"
        },
        "X2": {
          "desc": "empty array-like — result has zero rows",
          "example": "[]"
        }
      },
      "interaction_hints": ["labels", "fill_value", "method"],
      "invalid_cases": []
    },
    "columns": {
      "type": "array-like or None",
      "partitions": {
        "C0": {
          "desc": "None — column axis not changed",
          "example": "None"
        },
        "C1": {
          "desc": "non-empty array-like — new column labels including at least one new column",
          "example": "['http_status', 'user_agent']"
        },
        "C2": {
          "desc": "empty array-like — result has zero columns",
          "example": "[]"
        }
      },
      "interaction_hints": ["labels", "axis", "fill_value"],
      "invalid_cases": []
    },
    "axis": {
      "type": "int or str or None",
      "partitions": {
        "A0": {
          "desc": "None (default) — when labels is used, defaults to axis=0 (rows)",
          "example": "None"
        },
        "A1": {
          "desc": "0 or 'index' — labels targets the row axis",
          "example": "0  # or 'index'"
        },
        "A2": {
          "desc": "1 or 'columns' — labels targets the column axis",
          "example": "1  # or 'columns'"
        }
      },
      "interaction_hints": ["labels"],
      "invalid_cases": [
        {
          "desc": "axis value not in {0, 1, 'index', 'columns'}",
          "example": "df.reindex(['a','b'], axis=2)",
          "expected_exception": "ValueError",
          "note": "any integer or string not in the valid set raises ValueError",
          "source_ref": "R1"
        }
      ]
    },
    "method": {
      "type": "None or str",
      "partitions": {
        "M0": {
          "desc": "None (default) — no fill; new labels get fill_value (NaN by default)",
          "example": "None"
        },
        "M1": {
          "desc": "'pad' or 'ffill' — propagate last valid observation forward",
          "example": "'ffill'  # or 'pad'"
        },
        "M2": {
          "desc": "'backfill' or 'bfill' — use next valid observation to fill gap",
          "example": "'bfill'  # or 'backfill'"
        },
        "M3": {
          "desc": "'nearest' — use nearest (in label distance) valid observation",
          "example": "'nearest'"
        }
      },
      "interaction_hints": ["index", "limit", "tolerance"],
      "invalid_cases": [
        {
          "desc": "method string not in valid enum",
          "example": "df.reindex(new_index, method='linear')",
          "expected_exception": "ValueError",
          "note": null,
          "source_ref": "R1"
        },
        {
          "desc": "method used when axis index is non-monotonic",
          "example": "df_with_shuffled_index.reindex(new_index, method='ffill')",
          "expected_exception": "ValueError",
          "note": "doc states method only applicable to monotonically increasing/decreasing index",
          "source_ref": "R1"
        }
      ]
    },
    "copy": {
      "type": "bool",
      "partitions": {
        "CP0": {
          "desc": "not passed (default no_default) — no warning emitted",
          "example": "# omit copy kwarg entirely"
        },
        "CP1": {
          "desc": "explicitly passed True or False — deprecated, raises FutureWarning",
          "example": "copy=True  # or copy=False"
        }
      },
      "interaction_hints": [],
      "invalid_cases": []
    },
    "level": {
      "type": "int or level name or None",
      "partitions": {
        "LV0": {
          "desc": "None (default) — standard reindex without MultiIndex broadcast",
          "example": "None"
        },
        "LV1": {
          "desc": "int or level name — broadcast reindex across one MultiIndex level",
          "example": "0  # or 'first_level'"
        }
      },
      "interaction_hints": ["index"],
      "invalid_cases": []
    },
    "fill_value": {
      "type": "scalar",
      "partitions": {
        "F0": {
          "desc": "np.nan (default) — new labels receive NaN",
          "example": "np.nan"
        },
        "F1": {
          "desc": "dtype-compatible scalar — new labels receive fill_value without dtype promotion",
          "example": "0  # for numeric column"
        },
        "F2": {
          "desc": "dtype-incompatible scalar — silently promotes column dtype to object",
          "example": "'missing'  # for float column"
        }
      },
      "interaction_hints": ["index", "columns", "method"],
      "invalid_cases": []
    },
    "limit": {
      "type": "int or None",
      "partitions": {
        "LM0": {
          "desc": "None (default) — no cap on consecutive fill positions",
          "example": "None"
        },
        "LM1": {
          "desc": "positive integer — caps consecutive fill positions at N",
          "example": "2"
        }
      },
      "interaction_hints": ["method"],
      "invalid_cases": [
        {
          "desc": "limit set to a positive integer but method=None",
          "example": "df.reindex(new_index, limit=1)",
          "expected_exception": "ValueError",
          "note": "limit is only valid when a fill method is specified",
          "source_ref": "R1"
        }
      ]
    },
    "tolerance": {
      "type": "scalar or list-like or None",
      "partitions": {
        "T0": {
          "desc": "None (default) — no distance constraint on inexact matches",
          "example": "None"
        },
        "T1": {
          "desc": "scalar — single max-distance threshold applied to all new labels",
          "example": "0.5"
        },
        "T2": {
          "desc": "list-like same size as new index — per-label distance threshold",
          "example": "[0.1, 0.5, 1.0]  # same length as new_index"
        }
      },
      "interaction_hints": ["method", "index"],
      "invalid_cases": [
        {
          "desc": "tolerance is list-like but its length differs from new index length",
          "example": "df.reindex([1,2,3], method='nearest', tolerance=[0.1, 0.5])",
          "expected_exception": "ValueError",
          "note": "list-like tolerance must exactly match the size of the target index",
          "source_ref": "R1"
        }
      ]
    }
  },
  "post_conditions": [
    {
      "id": "P1",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Core usage: migrating a DataFrame to a new set of row labels where some rows don't exist. (2) Catches a bug where new labels accidentally receive 0 or empty-string instead of NaN when fill_value is unset. (3) Trigger on L2 (superset) isolates the new-label introduction path without conflating with value preservation.",
      "claim": "labels not present in the original index receive NaN in all columns when fill_value is not specified",
      "formal": [
        "new_labels = set(params.index) - set(original.index)",
        "for lbl in new_labels:",
        "  assert result.loc[lbl].isna().all()"
      ],
      "trigger": {
        "index": ["X1"],
        "fill_value": ["F0"]
      }
    },
    {
      "id": "P2",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Defensive coding: callers expect a fresh DataFrame and must not accidentally mutate the caller's original via shared memory. (2) Catches a Copy-on-Write regression where result is same object. (3) Trigger covers all partition combos because the identity guarantee must hold universally, not only in specific configurations.",
      "claim": "reindex always returns a new DataFrame object distinct from the original",
      "formal": [
        "assert result is not original"
      ],
      "trigger": {
        "index": ["X0", "X1", "X2"],
        "labels": ["L0", "L4"]
      }
    },
    {
      "id": "P3",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Migration scenario: existing codebases pass copy=True to force a copy; they should get a FutureWarning, not a silent ignore. (2) Catches a regression where the deprecation warning is accidentally removed in 3.x. (3) Narrow trigger on CP1 — only when copy is explicitly passed does the warning fire.",
      "claim": "explicitly passing copy=True or copy=False raises a FutureWarning deprecation warning",
      "formal": [
        "import warnings",
        "with warnings.catch_warnings(record=True) as w:",
        "  warnings.simplefilter('always')",
        "  result = original.reindex(new_index, copy=True)",
        "  assert any(issubclass(warning.category, FutureWarning) for warning in w)"
      ],
      "trigger": {
        "copy": ["CP1"]
      }
    },
    {
      "id": "P4",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Time-series upsampling: expanding a sparse date index and forward-filling known values. (2) Catches a bug where ffill carries the wrong row (off-by-one predecessor). (3) Trigger on M1+monotonic index isolates ffill path; L2 provides new labels that need filling.",
      "claim": "method='ffill' (or 'pad') fills each new label with the last original observation preceding it in index order",
      "formal": [
        "for new_lbl in (set(params.index) - set(original.index)):",
        "  preceding = max(lbl for lbl in original.index if lbl < new_lbl)",
        "  assert result.loc[new_lbl].equals(original.loc[preceding])"
      ],
      "trigger": {
        "index": ["X1"],
        "method": ["M1"]
      }
    },
    {
      "id": "P5",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Time-series backfilling: pre-expanding an index before known future values arrive. (2) Catches a bug where bfill carries the wrong row (off-by-one successor). (3) Trigger on M2 mirrors P4 but for the backward direction; complementary failure modes.",
      "claim": "method='bfill' (or 'backfill') fills each new label with the next original observation following it in index order",
      "formal": [
        "for new_lbl in (set(params.index) - set(original.index)):",
        "  following = min(lbl for lbl in original.index if lbl > new_lbl)",
        "  assert result.loc[new_lbl].equals(original.loc[following])"
      ],
      "trigger": {
        "index": ["X1"],
        "method": ["M2"]
      }
    },
    {
      "id": "P6",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Alias consistency: users who write 'pad' and users who write 'ffill' must observe identical behavior. (2) Catches a regression where one alias takes a different code path. (3) Combined trigger on M1 with both alias forms.",
      "claim": "'pad' is an exact alias for 'ffill' and produces bit-for-bit identical results",
      "formal": [
        "result_ffill = original.reindex(params.index, method='ffill')",
        "result_pad   = original.reindex(params.index, method='pad')",
        "assert result_ffill.equals(result_pad)"
      ],
      "trigger": {
        "method": ["M1"]
      }
    },
    {
      "id": "P7",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Alias consistency for backward direction. (2) Catches a divergence where 'backfill' and 'bfill' map to different implementations. (3) Mirrors P6 for M2.",
      "claim": "'backfill' is an exact alias for 'bfill' and produces bit-for-bit identical results",
      "formal": [
        "result_bfill     = original.reindex(params.index, method='bfill')",
        "result_backfill  = original.reindex(params.index, method='backfill')",
        "assert result_bfill.equals(result_backfill)"
      ],
      "trigger": {
        "method": ["M2"]
      }
    },
    {
      "id": "P8",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Controlled propagation: users set limit to prevent over-filling sparse regions. (2) Catches an off-by-one bug where limit=1 fills 2 positions or limit=2 fills 3. (3) Trigger on M1/M2+LM1 is the only configuration where limit has observable effect.",
      "claim": "limit=N caps forward/backward fill to at most N consecutive new-label positions; beyond N positions receive NaN",
      "formal": [
        "# arrange: 3 consecutive new labels after a known original row",
        "# call with method='ffill', limit=1",
        "assert not result.loc[new_lbl_1].isna().any()  # first consecutive filled",
        "assert result.loc[new_lbl_2].isna().all()       # second consecutive stays NaN",
        "assert result.loc[new_lbl_3].isna().all()       # third consecutive stays NaN"
      ],
      "trigger": {
        "method": ["M1"],
        "limit": ["LM1"]
      }
    },
    {
      "id": "P9",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Sentinel filling: analysts replace NaN with 0 or a placeholder string. (2) Catches a bug where fill_value is applied to existing rows or not applied to new ones. (3) Trigger F1 (compatible scalar) isolates dtype-stable path; combined with L2 to ensure new labels exist.",
      "claim": "fill_value replaces NaN for all newly introduced labels while leaving existing label values unchanged",
      "formal": [
        "new_labels = set(params.index) - set(original.index)",
        "kept_labels = set(params.index) & set(original.index)",
        "for lbl in new_labels:",
        "  assert (result.loc[lbl] == params.fill_value).all()",
        "for lbl in kept_labels:",
        "  assert result.loc[lbl].equals(original.loc[lbl])"
      ],
      "trigger": {
        "index": ["X1"],
        "fill_value": ["F1"]
      }
    },
    {
      "id": "P10",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Fuzzy time-series matching: reindex to a finer grid but only carry values for close timestamps. (2) Catches a bug where tolerance is ignored or inverted, filling labels that are too far. (3) T1+M3 is the minimal trigger to exercise scalar tolerance.",
      "claim": "when method='nearest' and tolerance is a scalar, new labels whose nearest original label is farther than tolerance receive NaN",
      "formal": [
        "for new_lbl in params.index:",
        "  nearest_dist = min(abs(new_lbl - orig_lbl) for orig_lbl in original.index)",
        "  if nearest_dist > params.tolerance:",
        "    assert result.loc[new_lbl].isna().all()",
        "  else:",
        "    assert not result.loc[new_lbl].isna().all()"
      ],
      "trigger": {
        "method": ["M3"],
        "tolerance": ["T1"]
      }
    },
    {
      "id": "P11",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Per-label tolerance: different positions in the new index may have different proximity requirements. (2) Catches a bug where list-like tolerance is applied as a scalar or the wrong element is used for each position. (3) T2+M3 is the only trigger combination that exercises per-label path.",
      "claim": "when tolerance is a list-like, each new label is matched independently against its own tolerance element",
      "formal": [
        "for i, new_lbl in enumerate(params.index):",
        "  nearest_dist = min(abs(new_lbl - orig_lbl) for orig_lbl in original.index)",
        "  if nearest_dist > params.tolerance[i]:",
        "    assert result.iloc[i].isna().all()",
        "  else:",
        "    assert not result.iloc[i].isna().all()"
      ],
      "trigger": {
        "method": ["M3"],
        "tolerance": ["T2"]
      }
    },
    {
      "id": "P12",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Nearest-match reindexing for numeric or datetime grids. (2) Catches a bug where 'nearest' always picks the predecessor (acting like ffill) or always the successor (acting like bfill). (3) Trigger on M3 without tolerance; non-tie case is unambiguous.",
      "claim": "method='nearest' selects the original label with the smallest absolute distance to the new label",
      "formal": [
        "for new_lbl in (set(params.index) - set(original.index)):",
        "  nearest_orig = min(original.index, key=lambda x: abs(x - new_lbl))",
        "  assert result.loc[new_lbl].equals(original.loc[nearest_orig])"
      ],
      "trigger": {
        "method": ["M3"],
        "tolerance": ["T0"]
      }
    },
    {
      "id": "P13",
      "track": "valid",
      "evidence": "indirect",
      "source_ref": "R1",
      "why": "(1) Prevents over-eager filling: users rely on existing NaN values being preserved when they reindex with a fill method. (2) Catches a bug where ffill/bfill accidentally fills pre-existing NaN values inside retained rows. (3) Trigger M1/M2 with X1 and a DataFrame that contains NaN in the original data.",
      "claim": "method-based fill only applies to newly introduced index positions; pre-existing NaN values in retained original rows are not filled",
      "formal": [
        "# original has NaN at row 'known_nan_row'",
        "# new index includes 'known_nan_row'",
        "assert result.loc['known_nan_row'].isna().all()"
      ],
      "trigger": {
        "index": ["X1"],
        "method": ["M1", "M2"]
      }
    },
    {
      "id": "P14",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Value correctness: retained rows must carry original data unchanged. (2) Catches a bug where reindexing shifts row values due to an indexing alignment error. (3) Trigger L2 isolates the retained-row path within a mixed superset reindex.",
      "claim": "labels present in both the original and new index have their exact original row values preserved in the result",
      "formal": [
        "kept_labels = set(params.index) & set(original.index)",
        "for lbl in kept_labels:",
        "  assert result.loc[lbl].equals(original.loc[lbl])"
      ],
      "trigger": {
        "labels": ["L2"]
      }
    },
    {
      "id": "P15",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Order contract: callers rely on result.index matching the requested order, especially when aligning multiple DataFrames. (2) Catches a bug where reindex returns rows in original order rather than the requested order. (3) All index partitions except L0 apply; L0 is irrelevant when index kwarg is used.",
      "claim": "the result index is exactly the requested new index in the same order",
      "formal": [
        "assert result.index.tolist() == list(params.index)"
      ],
      "trigger": {
        "index": ["X1", "X2"],
        "labels": ["L1", "L2", "L3", "L4", "L5"]
      }
    },
    {
      "id": "P16",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Orthogonality: reindexing rows must not silently alter column structure. (2) Catches a bug where column labels are dropped or reordered when only the row index changes. (3) Trigger C0 (columns not provided) combined with X1 confirms column-stability in a row-only reindex.",
      "claim": "column labels are unchanged when only the row index is reindexed",
      "formal": [
        "assert result.columns.tolist() == original.columns.tolist()"
      ],
      "trigger": {
        "index": ["X1"],
        "columns": ["C0"]
      }
    },
    {
      "id": "P17",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Identity idempotency: reindexing with the exact same index must not corrupt data. (2) Catches a dtype-promotion bug where even an identity reindex converts int to float. (3) L4 is the only partition that tests the no-op path; narrow scope prevents conflation with fill behavior.",
      "claim": "reindexing with the identical index in the same order produces a DataFrame equal to the original",
      "formal": [
        "assert result.equals(original)",
        "assert result is not original  # still a new object"
      ],
      "trigger": {
        "labels": ["L4"]
      }
    },
    {
      "id": "P18",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Dtype contract: int columns cannot store NaN so pandas must upcast to float64; callers must know to expect this. (2) Catches a regression where int columns are returned as int with silent NaN corruption. (3) Trigger X1+F0: new label introduction (causing NaN) on an int-column DataFrame.",
      "claim": "integer-dtype columns are promoted to float64 in the result when new labels introduce NaN values",
      "formal": [
        "# original has int64 column 'col'",
        "# new index introduces at least one new label",
        "assert result['col'].dtype == np.float64"
      ],
      "trigger": {
        "index": ["X1"],
        "fill_value": ["F0"]
      }
    },
    {
      "id": "P19",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Shape contract: callers who allocate arrays based on result length depend on len(result) == len(new_index). (2) Catches a bug where duplicate labels in new_index are deduplicated or extra rows are appended. (3) Covers all index partitions including edge cases L5/X2 (empty).",
      "claim": "the number of rows in the result equals the length of the requested new index",
      "formal": [
        "assert len(result) == len(params.index)"
      ],
      "trigger": {
        "index": ["X1", "X2"],
        "labels": ["L1", "L2", "L3", "L4", "L5"]
      }
    },
    {
      "id": "P20",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Return-type contract: downstream code that calls DataFrame methods on the result must not fail due to unexpected type. (2) Catches a bug where a fill method path returns a Series or NDFrame base class. (3) Universal trigger — no parameter combination should change the return type.",
      "claim": "the return value is always an instance of pd.DataFrame regardless of parameters",
      "formal": [
        "assert isinstance(result, pd.DataFrame)"
      ],
      "trigger": {
        "index": ["X0", "X1", "X2"],
        "columns": ["C0", "C1"],
        "method": ["M0", "M1", "M2", "M3"]
      }
    },
    {
      "id": "P21",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Column-axis reindexing: adding analytic columns that don't exist yet, or slimming a wide DataFrame. (2) Catches a bug where column reindex fills existing columns with NaN or leaves new columns unfilled. (3) Trigger C1+C0(no row change) isolates the column-axis path from row-axis changes.",
      "claim": "column reindexing fills new column labels with NaN and preserves all values in retained existing columns",
      "formal": [
        "new_cols = [c for c in params.columns if c not in original.columns]",
        "kept_cols = [c for c in params.columns if c in original.columns]",
        "for col in new_cols:",
        "  assert result[col].isna().all()",
        "for col in kept_cols:",
        "  assert result[col].equals(original[col])"
      ],
      "trigger": {
        "columns": ["C1"],
        "index": ["X0"]
      }
    },
    {
      "id": "P22",
      "track": "valid",
      "evidence": "implicit",
      "source_ref": null,
      "why": "(1) Original mutation guard: callers re-use the original DataFrame after reindex and must not find it modified. (2) Catches a bug where fill or reorder operations write back into the source. (3) Must be checked across all fill methods to ensure no path mutates the source.",
      "claim": "the original DataFrame is not mutated by any call to reindex",
      "formal": [
        "original_copy = original.copy(deep=True)",
        "_ = original.reindex(params.index, method=params.method, fill_value=params.fill_value)",
        "assert original.equals(original_copy)"
      ],
      "trigger": {
        "index": ["X1"],
        "method": ["M0", "M1", "M2", "M3"],
        "fill_value": ["F0", "F1"]
      }
    },
    {
      "id": "P23",
      "track": "valid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Dual-axis reindex: users reshape both rows and columns in one call. (2) Catches a bug where providing both index and columns only applies one axis. (3) Trigger X1+C1 is the only combination that exercises the two-axis path.",
      "claim": "when both index and columns are provided, the result is reindexed on both axes simultaneously",
      "formal": [
        "assert result.index.tolist() == list(params.index)",
        "assert result.columns.tolist() == list(params.columns)"
      ],
      "trigger": {
        "index": ["X1"],
        "columns": ["C1"]
      }
    },
    {
      "id": "E1",
      "track": "invalid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Guard against misuse: applying fill methods to unsorted data gives meaningless results; pandas should raise. (2) Catches a regression where the monotonicity check is silently skipped. (3) Non-monotonic index is the precise trigger — not just 'any index'.",
      "claim": "using method on a DataFrame whose axis index is non-monotonic raises ValueError",
      "formal": [
        "with pytest.raises(ValueError):",
        "  df_with_non_monotonic_index.reindex(new_index, method='ffill')"
      ],
      "trigger": {
        "method": ["non-monotonic index"]
      }
    },
    {
      "id": "E2",
      "track": "invalid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) API guard: method must be drawn from a fixed enum; free-form strings should fail loudly. (2) Catches a regression where unknown methods fall back silently to no-fill. (3) Exact trigger: any string outside the four valid method identifiers.",
      "claim": "passing an unrecognised string as method raises ValueError",
      "formal": [
        "with pytest.raises(ValueError):",
        "  original.reindex(new_index, method='linear')"
      ],
      "trigger": {
        "method": ["method string not in valid enum"]
      }
    },
    {
      "id": "E3",
      "track": "invalid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Safety: a misaligned per-label tolerance silently applies wrong thresholds; raising is safer. (2) Catches a bug where wrong-size tolerance is silently truncated or broadcast. (3) Trigger: list-like tolerance with length != len(new_index).",
      "claim": "passing a list-like tolerance whose length differs from the new index length raises ValueError",
      "formal": [
        "with pytest.raises(ValueError):",
        "  original.reindex([1, 2, 3], method='nearest', tolerance=[0.1, 0.5])"
      ],
      "trigger": {
        "tolerance": ["tolerance is list-like but its length differs from new index length"]
      }
    },
    {
      "id": "E4",
      "track": "invalid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) API contract: limit without a fill method is semantically undefined. (2) Catches a bug where limit is silently ignored when method=None. (3) Trigger: limit is a positive integer and method is None (default).",
      "claim": "setting limit without a fill method raises ValueError",
      "formal": [
        "with pytest.raises(ValueError):",
        "  original.reindex(new_index, limit=1)"
      ],
      "trigger": {
        "limit": ["limit set to a positive integer but method=None"]
      }
    },
    {
      "id": "E5",
      "track": "invalid",
      "evidence": "explicit",
      "source_ref": "R1",
      "why": "(1) Axis validation: callers who pass axis=2 or axis='row' must get a clear error rather than silent misbehavior. (2) Catches a regression where invalid axis values are silently coerced. (3) Trigger: any value not in {0, 1, 'index', 'columns'}.",
      "claim": "passing an invalid axis value raises ValueError",
      "formal": [
        "with pytest.raises(ValueError):",
        "  original.reindex(['a', 'b'], axis=2)"
      ],
      "trigger": {
        "axis": ["axis value not in {0, 1, 'index', 'columns'}"]
      }
    }
  ]
}
